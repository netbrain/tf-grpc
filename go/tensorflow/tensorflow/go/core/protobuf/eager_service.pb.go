// Code generated by protoc-gen-go. DO NOT EDIT.
// source: tensorflow/core/protobuf/eager_service.proto

package protobuf // import "github.com/netbrain/tf-grpc/go/tensorflow/tensorflow/go/core/protobuf"

import proto "github.com/golang/protobuf/proto"
import fmt "fmt"
import math "math"
import framework "github.com/netbrain/tf-grpc/go/tensorflow/tensorflow/go/core/framework"

import (
	context "golang.org/x/net/context"
	grpc "google.golang.org/grpc"
)

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

// This is a compile-time assertion to ensure that this generated file
// is compatible with the proto package it is being compiled against.
// A compilation error at this line likely means your copy of the
// proto package needs to be updated.
const _ = proto.ProtoPackageIsVersion2 // please upgrade the proto package

type RemoteTensorHandle struct {
	// The ID of the operation that produced this tensor.
	OpId int64 `protobuf:"varint,1,opt,name=op_id,json=opId,proto3" json:"op_id,omitempty"`
	// The index into the outputs of the operation that produced this tensor.
	OutputNum            int32    `protobuf:"varint,2,opt,name=output_num,json=outputNum,proto3" json:"output_num,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *RemoteTensorHandle) Reset()         { *m = RemoteTensorHandle{} }
func (m *RemoteTensorHandle) String() string { return proto.CompactTextString(m) }
func (*RemoteTensorHandle) ProtoMessage()    {}
func (*RemoteTensorHandle) Descriptor() ([]byte, []int) {
	return fileDescriptor_eager_service_30fc3da5fde2e8e6, []int{0}
}
func (m *RemoteTensorHandle) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_RemoteTensorHandle.Unmarshal(m, b)
}
func (m *RemoteTensorHandle) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_RemoteTensorHandle.Marshal(b, m, deterministic)
}
func (dst *RemoteTensorHandle) XXX_Merge(src proto.Message) {
	xxx_messageInfo_RemoteTensorHandle.Merge(dst, src)
}
func (m *RemoteTensorHandle) XXX_Size() int {
	return xxx_messageInfo_RemoteTensorHandle.Size(m)
}
func (m *RemoteTensorHandle) XXX_DiscardUnknown() {
	xxx_messageInfo_RemoteTensorHandle.DiscardUnknown(m)
}

var xxx_messageInfo_RemoteTensorHandle proto.InternalMessageInfo

func (m *RemoteTensorHandle) GetOpId() int64 {
	if m != nil {
		return m.OpId
	}
	return 0
}

func (m *RemoteTensorHandle) GetOutputNum() int32 {
	if m != nil {
		return m.OutputNum
	}
	return 0
}

// A proto representation of an eager operation.
type Operation struct {
	// A unique identifier for the operation. Set by the client so that the client
	// can uniquely identify the outputs of the scheduled operation.
	//
	// In the initial implementation, sending duplicate IDs has undefined
	// behaviour, but additional constraints may be placed upon this in the
	// future.
	Id     int64                 `protobuf:"varint,1,opt,name=id,proto3" json:"id,omitempty"`
	Name   string                `protobuf:"bytes,2,opt,name=name,proto3" json:"name,omitempty"`
	Inputs []*RemoteTensorHandle `protobuf:"bytes,3,rep,name=inputs,proto3" json:"inputs,omitempty"`
	// Control Operation IDs that will be respected when ops are re-ordered by
	// async execution. If async execution (+ op re-ordering) is not enabled, this
	// should have no effect.
	ControlOpIds         []int64                         `protobuf:"varint,4,rep,packed,name=control_op_ids,json=controlOpIds,proto3" json:"control_op_ids,omitempty"`
	Attrs                map[string]*framework.AttrValue `protobuf:"bytes,5,rep,name=attrs,proto3" json:"attrs,omitempty" protobuf_key:"bytes,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`
	Device               string                          `protobuf:"bytes,6,opt,name=device,proto3" json:"device,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                        `json:"-"`
	XXX_unrecognized     []byte                          `json:"-"`
	XXX_sizecache        int32                           `json:"-"`
}

func (m *Operation) Reset()         { *m = Operation{} }
func (m *Operation) String() string { return proto.CompactTextString(m) }
func (*Operation) ProtoMessage()    {}
func (*Operation) Descriptor() ([]byte, []int) {
	return fileDescriptor_eager_service_30fc3da5fde2e8e6, []int{1}
}
func (m *Operation) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_Operation.Unmarshal(m, b)
}
func (m *Operation) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_Operation.Marshal(b, m, deterministic)
}
func (dst *Operation) XXX_Merge(src proto.Message) {
	xxx_messageInfo_Operation.Merge(dst, src)
}
func (m *Operation) XXX_Size() int {
	return xxx_messageInfo_Operation.Size(m)
}
func (m *Operation) XXX_DiscardUnknown() {
	xxx_messageInfo_Operation.DiscardUnknown(m)
}

var xxx_messageInfo_Operation proto.InternalMessageInfo

func (m *Operation) GetId() int64 {
	if m != nil {
		return m.Id
	}
	return 0
}

func (m *Operation) GetName() string {
	if m != nil {
		return m.Name
	}
	return ""
}

func (m *Operation) GetInputs() []*RemoteTensorHandle {
	if m != nil {
		return m.Inputs
	}
	return nil
}

func (m *Operation) GetControlOpIds() []int64 {
	if m != nil {
		return m.ControlOpIds
	}
	return nil
}

func (m *Operation) GetAttrs() map[string]*framework.AttrValue {
	if m != nil {
		return m.Attrs
	}
	return nil
}

func (m *Operation) GetDevice() string {
	if m != nil {
		return m.Device
	}
	return ""
}

type QueueItem struct {
	// The remote executor should be able to handle either executing ops directly,
	// or releasing any unused tensor handles, since the tensor lifetime is
	// maintained by the client.
	//
	// Types that are valid to be assigned to Item:
	//	*QueueItem_HandleToDecref
	//	*QueueItem_Operation
	Item                 isQueueItem_Item `protobuf_oneof:"item"`
	XXX_NoUnkeyedLiteral struct{}         `json:"-"`
	XXX_unrecognized     []byte           `json:"-"`
	XXX_sizecache        int32            `json:"-"`
}

func (m *QueueItem) Reset()         { *m = QueueItem{} }
func (m *QueueItem) String() string { return proto.CompactTextString(m) }
func (*QueueItem) ProtoMessage()    {}
func (*QueueItem) Descriptor() ([]byte, []int) {
	return fileDescriptor_eager_service_30fc3da5fde2e8e6, []int{2}
}
func (m *QueueItem) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_QueueItem.Unmarshal(m, b)
}
func (m *QueueItem) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_QueueItem.Marshal(b, m, deterministic)
}
func (dst *QueueItem) XXX_Merge(src proto.Message) {
	xxx_messageInfo_QueueItem.Merge(dst, src)
}
func (m *QueueItem) XXX_Size() int {
	return xxx_messageInfo_QueueItem.Size(m)
}
func (m *QueueItem) XXX_DiscardUnknown() {
	xxx_messageInfo_QueueItem.DiscardUnknown(m)
}

var xxx_messageInfo_QueueItem proto.InternalMessageInfo

type isQueueItem_Item interface {
	isQueueItem_Item()
}

type QueueItem_HandleToDecref struct {
	HandleToDecref *RemoteTensorHandle `protobuf:"bytes,1,opt,name=handle_to_decref,json=handleToDecref,proto3,oneof"`
}

type QueueItem_Operation struct {
	Operation *Operation `protobuf:"bytes,2,opt,name=operation,proto3,oneof"`
}

func (*QueueItem_HandleToDecref) isQueueItem_Item() {}

func (*QueueItem_Operation) isQueueItem_Item() {}

func (m *QueueItem) GetItem() isQueueItem_Item {
	if m != nil {
		return m.Item
	}
	return nil
}

func (m *QueueItem) GetHandleToDecref() *RemoteTensorHandle {
	if x, ok := m.GetItem().(*QueueItem_HandleToDecref); ok {
		return x.HandleToDecref
	}
	return nil
}

func (m *QueueItem) GetOperation() *Operation {
	if x, ok := m.GetItem().(*QueueItem_Operation); ok {
		return x.Operation
	}
	return nil
}

// XXX_OneofFuncs is for the internal use of the proto package.
func (*QueueItem) XXX_OneofFuncs() (func(msg proto.Message, b *proto.Buffer) error, func(msg proto.Message, tag, wire int, b *proto.Buffer) (bool, error), func(msg proto.Message) (n int), []interface{}) {
	return _QueueItem_OneofMarshaler, _QueueItem_OneofUnmarshaler, _QueueItem_OneofSizer, []interface{}{
		(*QueueItem_HandleToDecref)(nil),
		(*QueueItem_Operation)(nil),
	}
}

func _QueueItem_OneofMarshaler(msg proto.Message, b *proto.Buffer) error {
	m := msg.(*QueueItem)
	// item
	switch x := m.Item.(type) {
	case *QueueItem_HandleToDecref:
		b.EncodeVarint(1<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.HandleToDecref); err != nil {
			return err
		}
	case *QueueItem_Operation:
		b.EncodeVarint(2<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Operation); err != nil {
			return err
		}
	case nil:
	default:
		return fmt.Errorf("QueueItem.Item has unexpected type %T", x)
	}
	return nil
}

func _QueueItem_OneofUnmarshaler(msg proto.Message, tag, wire int, b *proto.Buffer) (bool, error) {
	m := msg.(*QueueItem)
	switch tag {
	case 1: // item.handle_to_decref
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(RemoteTensorHandle)
		err := b.DecodeMessage(msg)
		m.Item = &QueueItem_HandleToDecref{msg}
		return true, err
	case 2: // item.operation
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(Operation)
		err := b.DecodeMessage(msg)
		m.Item = &QueueItem_Operation{msg}
		return true, err
	default:
		return false, nil
	}
}

func _QueueItem_OneofSizer(msg proto.Message) (n int) {
	m := msg.(*QueueItem)
	// item
	switch x := m.Item.(type) {
	case *QueueItem_HandleToDecref:
		s := proto.Size(x.HandleToDecref)
		n += 1 // tag and wire
		n += proto.SizeVarint(uint64(s))
		n += s
	case *QueueItem_Operation:
		s := proto.Size(x.Operation)
		n += 1 // tag and wire
		n += proto.SizeVarint(uint64(s))
		n += s
	case nil:
	default:
		panic(fmt.Sprintf("proto: unexpected type %T in oneof", x))
	}
	return n
}

type QueueResponse struct {
	Shape                []*framework.TensorShapeProto `protobuf:"bytes,1,rep,name=shape,proto3" json:"shape,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                      `json:"-"`
	XXX_unrecognized     []byte                        `json:"-"`
	XXX_sizecache        int32                         `json:"-"`
}

func (m *QueueResponse) Reset()         { *m = QueueResponse{} }
func (m *QueueResponse) String() string { return proto.CompactTextString(m) }
func (*QueueResponse) ProtoMessage()    {}
func (*QueueResponse) Descriptor() ([]byte, []int) {
	return fileDescriptor_eager_service_30fc3da5fde2e8e6, []int{3}
}
func (m *QueueResponse) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_QueueResponse.Unmarshal(m, b)
}
func (m *QueueResponse) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_QueueResponse.Marshal(b, m, deterministic)
}
func (dst *QueueResponse) XXX_Merge(src proto.Message) {
	xxx_messageInfo_QueueResponse.Merge(dst, src)
}
func (m *QueueResponse) XXX_Size() int {
	return xxx_messageInfo_QueueResponse.Size(m)
}
func (m *QueueResponse) XXX_DiscardUnknown() {
	xxx_messageInfo_QueueResponse.DiscardUnknown(m)
}

var xxx_messageInfo_QueueResponse proto.InternalMessageInfo

func (m *QueueResponse) GetShape() []*framework.TensorShapeProto {
	if m != nil {
		return m.Shape
	}
	return nil
}

type CreateContextRequest struct {
	// Identifies the full cluster, and this particular worker's position within.
	ServerDef *ServerDef `protobuf:"bytes,1,opt,name=server_def,json=serverDef,proto3" json:"server_def,omitempty"`
	// Whether the ops on the worker should be executed synchronously or
	// asynchronously. By default, ops are executed synchronously.
	Async bool `protobuf:"varint,2,opt,name=async,proto3" json:"async,omitempty"`
	// Number of seconds to keep the context alive. If more than keep_alive_secs
	// has passed since a particular context has been communicated with, it will
	// be garbage collected.
	KeepAliveSecs int64 `protobuf:"varint,3,opt,name=keep_alive_secs,json=keepAliveSecs,proto3" json:"keep_alive_secs,omitempty"`
	// This is the version for all the ops that will be enqueued by the client.
	VersionDef *framework.VersionDef `protobuf:"bytes,4,opt,name=version_def,json=versionDef,proto3" json:"version_def,omitempty"`
	// This ID will be used for all future communications. It is essential that
	// both ends use this ID for selecting a rendezvous to get everything to
	// match.
	RendezvousId         int64    `protobuf:"varint,5,opt,name=rendezvous_id,json=rendezvousId,proto3" json:"rendezvous_id,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *CreateContextRequest) Reset()         { *m = CreateContextRequest{} }
func (m *CreateContextRequest) String() string { return proto.CompactTextString(m) }
func (*CreateContextRequest) ProtoMessage()    {}
func (*CreateContextRequest) Descriptor() ([]byte, []int) {
	return fileDescriptor_eager_service_30fc3da5fde2e8e6, []int{4}
}
func (m *CreateContextRequest) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_CreateContextRequest.Unmarshal(m, b)
}
func (m *CreateContextRequest) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_CreateContextRequest.Marshal(b, m, deterministic)
}
func (dst *CreateContextRequest) XXX_Merge(src proto.Message) {
	xxx_messageInfo_CreateContextRequest.Merge(dst, src)
}
func (m *CreateContextRequest) XXX_Size() int {
	return xxx_messageInfo_CreateContextRequest.Size(m)
}
func (m *CreateContextRequest) XXX_DiscardUnknown() {
	xxx_messageInfo_CreateContextRequest.DiscardUnknown(m)
}

var xxx_messageInfo_CreateContextRequest proto.InternalMessageInfo

func (m *CreateContextRequest) GetServerDef() *ServerDef {
	if m != nil {
		return m.ServerDef
	}
	return nil
}

func (m *CreateContextRequest) GetAsync() bool {
	if m != nil {
		return m.Async
	}
	return false
}

func (m *CreateContextRequest) GetKeepAliveSecs() int64 {
	if m != nil {
		return m.KeepAliveSecs
	}
	return 0
}

func (m *CreateContextRequest) GetVersionDef() *framework.VersionDef {
	if m != nil {
		return m.VersionDef
	}
	return nil
}

func (m *CreateContextRequest) GetRendezvousId() int64 {
	if m != nil {
		return m.RendezvousId
	}
	return 0
}

type CreateContextResponse struct {
	// The ID of the created context. This is usually a randomly generated number,
	// that will be used to identify the context in future requests to the
	// service. Contexts are not persisted through server restarts.
	ContextId uint64 `protobuf:"fixed64,1,opt,name=context_id,json=contextId,proto3" json:"context_id,omitempty"`
	// List of devices that are locally accessible to the worker.
	DeviceAttributes     []*framework.DeviceAttributes `protobuf:"bytes,2,rep,name=device_attributes,json=deviceAttributes,proto3" json:"device_attributes,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                      `json:"-"`
	XXX_unrecognized     []byte                        `json:"-"`
	XXX_sizecache        int32                         `json:"-"`
}

func (m *CreateContextResponse) Reset()         { *m = CreateContextResponse{} }
func (m *CreateContextResponse) String() string { return proto.CompactTextString(m) }
func (*CreateContextResponse) ProtoMessage()    {}
func (*CreateContextResponse) Descriptor() ([]byte, []int) {
	return fileDescriptor_eager_service_30fc3da5fde2e8e6, []int{5}
}
func (m *CreateContextResponse) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_CreateContextResponse.Unmarshal(m, b)
}
func (m *CreateContextResponse) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_CreateContextResponse.Marshal(b, m, deterministic)
}
func (dst *CreateContextResponse) XXX_Merge(src proto.Message) {
	xxx_messageInfo_CreateContextResponse.Merge(dst, src)
}
func (m *CreateContextResponse) XXX_Size() int {
	return xxx_messageInfo_CreateContextResponse.Size(m)
}
func (m *CreateContextResponse) XXX_DiscardUnknown() {
	xxx_messageInfo_CreateContextResponse.DiscardUnknown(m)
}

var xxx_messageInfo_CreateContextResponse proto.InternalMessageInfo

func (m *CreateContextResponse) GetContextId() uint64 {
	if m != nil {
		return m.ContextId
	}
	return 0
}

func (m *CreateContextResponse) GetDeviceAttributes() []*framework.DeviceAttributes {
	if m != nil {
		return m.DeviceAttributes
	}
	return nil
}

type EnqueueRequest struct {
	ContextId            uint64       `protobuf:"fixed64,1,opt,name=context_id,json=contextId,proto3" json:"context_id,omitempty"`
	Queue                []*QueueItem `protobuf:"bytes,3,rep,name=queue,proto3" json:"queue,omitempty"`
	XXX_NoUnkeyedLiteral struct{}     `json:"-"`
	XXX_unrecognized     []byte       `json:"-"`
	XXX_sizecache        int32        `json:"-"`
}

func (m *EnqueueRequest) Reset()         { *m = EnqueueRequest{} }
func (m *EnqueueRequest) String() string { return proto.CompactTextString(m) }
func (*EnqueueRequest) ProtoMessage()    {}
func (*EnqueueRequest) Descriptor() ([]byte, []int) {
	return fileDescriptor_eager_service_30fc3da5fde2e8e6, []int{6}
}
func (m *EnqueueRequest) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_EnqueueRequest.Unmarshal(m, b)
}
func (m *EnqueueRequest) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_EnqueueRequest.Marshal(b, m, deterministic)
}
func (dst *EnqueueRequest) XXX_Merge(src proto.Message) {
	xxx_messageInfo_EnqueueRequest.Merge(dst, src)
}
func (m *EnqueueRequest) XXX_Size() int {
	return xxx_messageInfo_EnqueueRequest.Size(m)
}
func (m *EnqueueRequest) XXX_DiscardUnknown() {
	xxx_messageInfo_EnqueueRequest.DiscardUnknown(m)
}

var xxx_messageInfo_EnqueueRequest proto.InternalMessageInfo

func (m *EnqueueRequest) GetContextId() uint64 {
	if m != nil {
		return m.ContextId
	}
	return 0
}

func (m *EnqueueRequest) GetQueue() []*QueueItem {
	if m != nil {
		return m.Queue
	}
	return nil
}

type EnqueueResponse struct {
	// A single operation response for every item in the request.
	QueueResponse        []*QueueResponse `protobuf:"bytes,1,rep,name=queue_response,json=queueResponse,proto3" json:"queue_response,omitempty"`
	XXX_NoUnkeyedLiteral struct{}         `json:"-"`
	XXX_unrecognized     []byte           `json:"-"`
	XXX_sizecache        int32            `json:"-"`
}

func (m *EnqueueResponse) Reset()         { *m = EnqueueResponse{} }
func (m *EnqueueResponse) String() string { return proto.CompactTextString(m) }
func (*EnqueueResponse) ProtoMessage()    {}
func (*EnqueueResponse) Descriptor() ([]byte, []int) {
	return fileDescriptor_eager_service_30fc3da5fde2e8e6, []int{7}
}
func (m *EnqueueResponse) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_EnqueueResponse.Unmarshal(m, b)
}
func (m *EnqueueResponse) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_EnqueueResponse.Marshal(b, m, deterministic)
}
func (dst *EnqueueResponse) XXX_Merge(src proto.Message) {
	xxx_messageInfo_EnqueueResponse.Merge(dst, src)
}
func (m *EnqueueResponse) XXX_Size() int {
	return xxx_messageInfo_EnqueueResponse.Size(m)
}
func (m *EnqueueResponse) XXX_DiscardUnknown() {
	xxx_messageInfo_EnqueueResponse.DiscardUnknown(m)
}

var xxx_messageInfo_EnqueueResponse proto.InternalMessageInfo

func (m *EnqueueResponse) GetQueueResponse() []*QueueResponse {
	if m != nil {
		return m.QueueResponse
	}
	return nil
}

type WaitQueueDoneRequest struct {
	ContextId uint64 `protobuf:"fixed64,1,opt,name=context_id,json=contextId,proto3" json:"context_id,omitempty"`
	// Ids to wait on. If empty, wait on everything currently pending.
	OpId                 []int64  `protobuf:"varint,2,rep,packed,name=op_id,json=opId,proto3" json:"op_id,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *WaitQueueDoneRequest) Reset()         { *m = WaitQueueDoneRequest{} }
func (m *WaitQueueDoneRequest) String() string { return proto.CompactTextString(m) }
func (*WaitQueueDoneRequest) ProtoMessage()    {}
func (*WaitQueueDoneRequest) Descriptor() ([]byte, []int) {
	return fileDescriptor_eager_service_30fc3da5fde2e8e6, []int{8}
}
func (m *WaitQueueDoneRequest) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_WaitQueueDoneRequest.Unmarshal(m, b)
}
func (m *WaitQueueDoneRequest) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_WaitQueueDoneRequest.Marshal(b, m, deterministic)
}
func (dst *WaitQueueDoneRequest) XXX_Merge(src proto.Message) {
	xxx_messageInfo_WaitQueueDoneRequest.Merge(dst, src)
}
func (m *WaitQueueDoneRequest) XXX_Size() int {
	return xxx_messageInfo_WaitQueueDoneRequest.Size(m)
}
func (m *WaitQueueDoneRequest) XXX_DiscardUnknown() {
	xxx_messageInfo_WaitQueueDoneRequest.DiscardUnknown(m)
}

var xxx_messageInfo_WaitQueueDoneRequest proto.InternalMessageInfo

func (m *WaitQueueDoneRequest) GetContextId() uint64 {
	if m != nil {
		return m.ContextId
	}
	return 0
}

func (m *WaitQueueDoneRequest) GetOpId() []int64 {
	if m != nil {
		return m.OpId
	}
	return nil
}

type WaitQueueDoneResponse struct {
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *WaitQueueDoneResponse) Reset()         { *m = WaitQueueDoneResponse{} }
func (m *WaitQueueDoneResponse) String() string { return proto.CompactTextString(m) }
func (*WaitQueueDoneResponse) ProtoMessage()    {}
func (*WaitQueueDoneResponse) Descriptor() ([]byte, []int) {
	return fileDescriptor_eager_service_30fc3da5fde2e8e6, []int{9}
}
func (m *WaitQueueDoneResponse) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_WaitQueueDoneResponse.Unmarshal(m, b)
}
func (m *WaitQueueDoneResponse) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_WaitQueueDoneResponse.Marshal(b, m, deterministic)
}
func (dst *WaitQueueDoneResponse) XXX_Merge(src proto.Message) {
	xxx_messageInfo_WaitQueueDoneResponse.Merge(dst, src)
}
func (m *WaitQueueDoneResponse) XXX_Size() int {
	return xxx_messageInfo_WaitQueueDoneResponse.Size(m)
}
func (m *WaitQueueDoneResponse) XXX_DiscardUnknown() {
	xxx_messageInfo_WaitQueueDoneResponse.DiscardUnknown(m)
}

var xxx_messageInfo_WaitQueueDoneResponse proto.InternalMessageInfo

type KeepAliveRequest struct {
	ContextId            uint64   `protobuf:"fixed64,1,opt,name=context_id,json=contextId,proto3" json:"context_id,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *KeepAliveRequest) Reset()         { *m = KeepAliveRequest{} }
func (m *KeepAliveRequest) String() string { return proto.CompactTextString(m) }
func (*KeepAliveRequest) ProtoMessage()    {}
func (*KeepAliveRequest) Descriptor() ([]byte, []int) {
	return fileDescriptor_eager_service_30fc3da5fde2e8e6, []int{10}
}
func (m *KeepAliveRequest) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_KeepAliveRequest.Unmarshal(m, b)
}
func (m *KeepAliveRequest) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_KeepAliveRequest.Marshal(b, m, deterministic)
}
func (dst *KeepAliveRequest) XXX_Merge(src proto.Message) {
	xxx_messageInfo_KeepAliveRequest.Merge(dst, src)
}
func (m *KeepAliveRequest) XXX_Size() int {
	return xxx_messageInfo_KeepAliveRequest.Size(m)
}
func (m *KeepAliveRequest) XXX_DiscardUnknown() {
	xxx_messageInfo_KeepAliveRequest.DiscardUnknown(m)
}

var xxx_messageInfo_KeepAliveRequest proto.InternalMessageInfo

func (m *KeepAliveRequest) GetContextId() uint64 {
	if m != nil {
		return m.ContextId
	}
	return 0
}

type KeepAliveResponse struct {
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *KeepAliveResponse) Reset()         { *m = KeepAliveResponse{} }
func (m *KeepAliveResponse) String() string { return proto.CompactTextString(m) }
func (*KeepAliveResponse) ProtoMessage()    {}
func (*KeepAliveResponse) Descriptor() ([]byte, []int) {
	return fileDescriptor_eager_service_30fc3da5fde2e8e6, []int{11}
}
func (m *KeepAliveResponse) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_KeepAliveResponse.Unmarshal(m, b)
}
func (m *KeepAliveResponse) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_KeepAliveResponse.Marshal(b, m, deterministic)
}
func (dst *KeepAliveResponse) XXX_Merge(src proto.Message) {
	xxx_messageInfo_KeepAliveResponse.Merge(dst, src)
}
func (m *KeepAliveResponse) XXX_Size() int {
	return xxx_messageInfo_KeepAliveResponse.Size(m)
}
func (m *KeepAliveResponse) XXX_DiscardUnknown() {
	xxx_messageInfo_KeepAliveResponse.DiscardUnknown(m)
}

var xxx_messageInfo_KeepAliveResponse proto.InternalMessageInfo

type CloseContextRequest struct {
	ContextId            uint64   `protobuf:"fixed64,1,opt,name=context_id,json=contextId,proto3" json:"context_id,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *CloseContextRequest) Reset()         { *m = CloseContextRequest{} }
func (m *CloseContextRequest) String() string { return proto.CompactTextString(m) }
func (*CloseContextRequest) ProtoMessage()    {}
func (*CloseContextRequest) Descriptor() ([]byte, []int) {
	return fileDescriptor_eager_service_30fc3da5fde2e8e6, []int{12}
}
func (m *CloseContextRequest) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_CloseContextRequest.Unmarshal(m, b)
}
func (m *CloseContextRequest) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_CloseContextRequest.Marshal(b, m, deterministic)
}
func (dst *CloseContextRequest) XXX_Merge(src proto.Message) {
	xxx_messageInfo_CloseContextRequest.Merge(dst, src)
}
func (m *CloseContextRequest) XXX_Size() int {
	return xxx_messageInfo_CloseContextRequest.Size(m)
}
func (m *CloseContextRequest) XXX_DiscardUnknown() {
	xxx_messageInfo_CloseContextRequest.DiscardUnknown(m)
}

var xxx_messageInfo_CloseContextRequest proto.InternalMessageInfo

func (m *CloseContextRequest) GetContextId() uint64 {
	if m != nil {
		return m.ContextId
	}
	return 0
}

type CloseContextResponse struct {
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *CloseContextResponse) Reset()         { *m = CloseContextResponse{} }
func (m *CloseContextResponse) String() string { return proto.CompactTextString(m) }
func (*CloseContextResponse) ProtoMessage()    {}
func (*CloseContextResponse) Descriptor() ([]byte, []int) {
	return fileDescriptor_eager_service_30fc3da5fde2e8e6, []int{13}
}
func (m *CloseContextResponse) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_CloseContextResponse.Unmarshal(m, b)
}
func (m *CloseContextResponse) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_CloseContextResponse.Marshal(b, m, deterministic)
}
func (dst *CloseContextResponse) XXX_Merge(src proto.Message) {
	xxx_messageInfo_CloseContextResponse.Merge(dst, src)
}
func (m *CloseContextResponse) XXX_Size() int {
	return xxx_messageInfo_CloseContextResponse.Size(m)
}
func (m *CloseContextResponse) XXX_DiscardUnknown() {
	xxx_messageInfo_CloseContextResponse.DiscardUnknown(m)
}

var xxx_messageInfo_CloseContextResponse proto.InternalMessageInfo

type RegisterFunctionRequest struct {
	ContextId            uint64                 `protobuf:"fixed64,1,opt,name=context_id,json=contextId,proto3" json:"context_id,omitempty"`
	FunctionDef          *framework.FunctionDef `protobuf:"bytes,2,opt,name=function_def,json=functionDef,proto3" json:"function_def,omitempty"`
	XXX_NoUnkeyedLiteral struct{}               `json:"-"`
	XXX_unrecognized     []byte                 `json:"-"`
	XXX_sizecache        int32                  `json:"-"`
}

func (m *RegisterFunctionRequest) Reset()         { *m = RegisterFunctionRequest{} }
func (m *RegisterFunctionRequest) String() string { return proto.CompactTextString(m) }
func (*RegisterFunctionRequest) ProtoMessage()    {}
func (*RegisterFunctionRequest) Descriptor() ([]byte, []int) {
	return fileDescriptor_eager_service_30fc3da5fde2e8e6, []int{14}
}
func (m *RegisterFunctionRequest) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_RegisterFunctionRequest.Unmarshal(m, b)
}
func (m *RegisterFunctionRequest) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_RegisterFunctionRequest.Marshal(b, m, deterministic)
}
func (dst *RegisterFunctionRequest) XXX_Merge(src proto.Message) {
	xxx_messageInfo_RegisterFunctionRequest.Merge(dst, src)
}
func (m *RegisterFunctionRequest) XXX_Size() int {
	return xxx_messageInfo_RegisterFunctionRequest.Size(m)
}
func (m *RegisterFunctionRequest) XXX_DiscardUnknown() {
	xxx_messageInfo_RegisterFunctionRequest.DiscardUnknown(m)
}

var xxx_messageInfo_RegisterFunctionRequest proto.InternalMessageInfo

func (m *RegisterFunctionRequest) GetContextId() uint64 {
	if m != nil {
		return m.ContextId
	}
	return 0
}

func (m *RegisterFunctionRequest) GetFunctionDef() *framework.FunctionDef {
	if m != nil {
		return m.FunctionDef
	}
	return nil
}

type RegisterFunctionResponse struct {
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *RegisterFunctionResponse) Reset()         { *m = RegisterFunctionResponse{} }
func (m *RegisterFunctionResponse) String() string { return proto.CompactTextString(m) }
func (*RegisterFunctionResponse) ProtoMessage()    {}
func (*RegisterFunctionResponse) Descriptor() ([]byte, []int) {
	return fileDescriptor_eager_service_30fc3da5fde2e8e6, []int{15}
}
func (m *RegisterFunctionResponse) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_RegisterFunctionResponse.Unmarshal(m, b)
}
func (m *RegisterFunctionResponse) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_RegisterFunctionResponse.Marshal(b, m, deterministic)
}
func (dst *RegisterFunctionResponse) XXX_Merge(src proto.Message) {
	xxx_messageInfo_RegisterFunctionResponse.Merge(dst, src)
}
func (m *RegisterFunctionResponse) XXX_Size() int {
	return xxx_messageInfo_RegisterFunctionResponse.Size(m)
}
func (m *RegisterFunctionResponse) XXX_DiscardUnknown() {
	xxx_messageInfo_RegisterFunctionResponse.DiscardUnknown(m)
}

var xxx_messageInfo_RegisterFunctionResponse proto.InternalMessageInfo

type SendTensorRequest struct {
	ContextId uint64 `protobuf:"fixed64,1,opt,name=context_id,json=contextId,proto3" json:"context_id,omitempty"`
	// All remote tensors are identified by <Op ID, Output num>. To mimic this
	// situation when directly sending tensors, we include an "artificial" op ID
	// (which would have corresponded to the _Recv op when not using SendTensor).
	OpId int64 `protobuf:"varint,2,opt,name=op_id,json=opId,proto3" json:"op_id,omitempty"`
	// The index within the repeated field is the output number that will help
	// uniquely identify (along with the above op_id) the particular tensor.
	Tensors []*framework.TensorProto `protobuf:"bytes,3,rep,name=tensors,proto3" json:"tensors,omitempty"`
	// The device on which the tensors should be resident.
	DeviceName           string   `protobuf:"bytes,4,opt,name=device_name,json=deviceName,proto3" json:"device_name,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *SendTensorRequest) Reset()         { *m = SendTensorRequest{} }
func (m *SendTensorRequest) String() string { return proto.CompactTextString(m) }
func (*SendTensorRequest) ProtoMessage()    {}
func (*SendTensorRequest) Descriptor() ([]byte, []int) {
	return fileDescriptor_eager_service_30fc3da5fde2e8e6, []int{16}
}
func (m *SendTensorRequest) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_SendTensorRequest.Unmarshal(m, b)
}
func (m *SendTensorRequest) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_SendTensorRequest.Marshal(b, m, deterministic)
}
func (dst *SendTensorRequest) XXX_Merge(src proto.Message) {
	xxx_messageInfo_SendTensorRequest.Merge(dst, src)
}
func (m *SendTensorRequest) XXX_Size() int {
	return xxx_messageInfo_SendTensorRequest.Size(m)
}
func (m *SendTensorRequest) XXX_DiscardUnknown() {
	xxx_messageInfo_SendTensorRequest.DiscardUnknown(m)
}

var xxx_messageInfo_SendTensorRequest proto.InternalMessageInfo

func (m *SendTensorRequest) GetContextId() uint64 {
	if m != nil {
		return m.ContextId
	}
	return 0
}

func (m *SendTensorRequest) GetOpId() int64 {
	if m != nil {
		return m.OpId
	}
	return 0
}

func (m *SendTensorRequest) GetTensors() []*framework.TensorProto {
	if m != nil {
		return m.Tensors
	}
	return nil
}

func (m *SendTensorRequest) GetDeviceName() string {
	if m != nil {
		return m.DeviceName
	}
	return ""
}

type SendTensorResponse struct {
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *SendTensorResponse) Reset()         { *m = SendTensorResponse{} }
func (m *SendTensorResponse) String() string { return proto.CompactTextString(m) }
func (*SendTensorResponse) ProtoMessage()    {}
func (*SendTensorResponse) Descriptor() ([]byte, []int) {
	return fileDescriptor_eager_service_30fc3da5fde2e8e6, []int{17}
}
func (m *SendTensorResponse) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_SendTensorResponse.Unmarshal(m, b)
}
func (m *SendTensorResponse) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_SendTensorResponse.Marshal(b, m, deterministic)
}
func (dst *SendTensorResponse) XXX_Merge(src proto.Message) {
	xxx_messageInfo_SendTensorResponse.Merge(dst, src)
}
func (m *SendTensorResponse) XXX_Size() int {
	return xxx_messageInfo_SendTensorResponse.Size(m)
}
func (m *SendTensorResponse) XXX_DiscardUnknown() {
	xxx_messageInfo_SendTensorResponse.DiscardUnknown(m)
}

var xxx_messageInfo_SendTensorResponse proto.InternalMessageInfo

func init() {
	proto.RegisterType((*RemoteTensorHandle)(nil), "tensorflow.eager.RemoteTensorHandle")
	proto.RegisterType((*Operation)(nil), "tensorflow.eager.Operation")
	proto.RegisterMapType((map[string]*framework.AttrValue)(nil), "tensorflow.eager.Operation.AttrsEntry")
	proto.RegisterType((*QueueItem)(nil), "tensorflow.eager.QueueItem")
	proto.RegisterType((*QueueResponse)(nil), "tensorflow.eager.QueueResponse")
	proto.RegisterType((*CreateContextRequest)(nil), "tensorflow.eager.CreateContextRequest")
	proto.RegisterType((*CreateContextResponse)(nil), "tensorflow.eager.CreateContextResponse")
	proto.RegisterType((*EnqueueRequest)(nil), "tensorflow.eager.EnqueueRequest")
	proto.RegisterType((*EnqueueResponse)(nil), "tensorflow.eager.EnqueueResponse")
	proto.RegisterType((*WaitQueueDoneRequest)(nil), "tensorflow.eager.WaitQueueDoneRequest")
	proto.RegisterType((*WaitQueueDoneResponse)(nil), "tensorflow.eager.WaitQueueDoneResponse")
	proto.RegisterType((*KeepAliveRequest)(nil), "tensorflow.eager.KeepAliveRequest")
	proto.RegisterType((*KeepAliveResponse)(nil), "tensorflow.eager.KeepAliveResponse")
	proto.RegisterType((*CloseContextRequest)(nil), "tensorflow.eager.CloseContextRequest")
	proto.RegisterType((*CloseContextResponse)(nil), "tensorflow.eager.CloseContextResponse")
	proto.RegisterType((*RegisterFunctionRequest)(nil), "tensorflow.eager.RegisterFunctionRequest")
	proto.RegisterType((*RegisterFunctionResponse)(nil), "tensorflow.eager.RegisterFunctionResponse")
	proto.RegisterType((*SendTensorRequest)(nil), "tensorflow.eager.SendTensorRequest")
	proto.RegisterType((*SendTensorResponse)(nil), "tensorflow.eager.SendTensorResponse")
}

// Reference imports to suppress errors if they are not otherwise used.
var _ context.Context
var _ grpc.ClientConn

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
const _ = grpc.SupportPackageIsVersion4

// EagerServiceClient is the client API for EagerService service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://godoc.org/google.golang.org/grpc#ClientConn.NewStream.
type EagerServiceClient interface {
	// This initializes the worker, informing it about the other workers in the
	// cluster and exchanging authentication tokens which will be used in all
	// other RPCs to detect whether the worker has restarted.
	CreateContext(ctx context.Context, in *CreateContextRequest, opts ...grpc.CallOption) (*CreateContextResponse, error)
	// This takes a list of Execute and DeleteTensorHandle operations and enqueues
	// (in async mode) or executes (in sync mode) them on the remote server.
	// All outputs of ops which were not explicitly deleted with
	// DeleteTensorHandle entries will be assumed to be alive and are usable by
	// future calls to Enqueue.
	Enqueue(ctx context.Context, in *EnqueueRequest, opts ...grpc.CallOption) (*EnqueueResponse, error)
	// Takes a set of op IDs and waits until those ops are done. Returns any error
	// in the stream so far.
	WaitQueueDone(ctx context.Context, in *WaitQueueDoneRequest, opts ...grpc.CallOption) (*WaitQueueDoneResponse, error)
	// Contexts are always created with a deadline and no RPCs within a deadline
	// will trigger a context garbage collection. KeepAlive calls can be used to
	// delay this.
	KeepAlive(ctx context.Context, in *KeepAliveRequest, opts ...grpc.CallOption) (*KeepAliveResponse, error)
	// Closes the context. No calls to other methods using the existing context ID
	// are valid after this.
	CloseContext(ctx context.Context, in *CloseContextRequest, opts ...grpc.CallOption) (*CloseContextResponse, error)
	// Takes a FunctionDef and makes it enqueable on the remote worker.
	RegisterFunction(ctx context.Context, in *RegisterFunctionRequest, opts ...grpc.CallOption) (*RegisterFunctionResponse, error)
	// An RPC to push tensors to the server. At times, certain environments don't
	// allow the server to connect back to the client.
	SendTensor(ctx context.Context, in *SendTensorRequest, opts ...grpc.CallOption) (*SendTensorResponse, error)
}

type eagerServiceClient struct {
	cc *grpc.ClientConn
}

func NewEagerServiceClient(cc *grpc.ClientConn) EagerServiceClient {
	return &eagerServiceClient{cc}
}

func (c *eagerServiceClient) CreateContext(ctx context.Context, in *CreateContextRequest, opts ...grpc.CallOption) (*CreateContextResponse, error) {
	out := new(CreateContextResponse)
	err := c.cc.Invoke(ctx, "/tensorflow.eager.EagerService/CreateContext", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *eagerServiceClient) Enqueue(ctx context.Context, in *EnqueueRequest, opts ...grpc.CallOption) (*EnqueueResponse, error) {
	out := new(EnqueueResponse)
	err := c.cc.Invoke(ctx, "/tensorflow.eager.EagerService/Enqueue", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *eagerServiceClient) WaitQueueDone(ctx context.Context, in *WaitQueueDoneRequest, opts ...grpc.CallOption) (*WaitQueueDoneResponse, error) {
	out := new(WaitQueueDoneResponse)
	err := c.cc.Invoke(ctx, "/tensorflow.eager.EagerService/WaitQueueDone", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *eagerServiceClient) KeepAlive(ctx context.Context, in *KeepAliveRequest, opts ...grpc.CallOption) (*KeepAliveResponse, error) {
	out := new(KeepAliveResponse)
	err := c.cc.Invoke(ctx, "/tensorflow.eager.EagerService/KeepAlive", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *eagerServiceClient) CloseContext(ctx context.Context, in *CloseContextRequest, opts ...grpc.CallOption) (*CloseContextResponse, error) {
	out := new(CloseContextResponse)
	err := c.cc.Invoke(ctx, "/tensorflow.eager.EagerService/CloseContext", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *eagerServiceClient) RegisterFunction(ctx context.Context, in *RegisterFunctionRequest, opts ...grpc.CallOption) (*RegisterFunctionResponse, error) {
	out := new(RegisterFunctionResponse)
	err := c.cc.Invoke(ctx, "/tensorflow.eager.EagerService/RegisterFunction", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *eagerServiceClient) SendTensor(ctx context.Context, in *SendTensorRequest, opts ...grpc.CallOption) (*SendTensorResponse, error) {
	out := new(SendTensorResponse)
	err := c.cc.Invoke(ctx, "/tensorflow.eager.EagerService/SendTensor", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// EagerServiceServer is the server API for EagerService service.
type EagerServiceServer interface {
	// This initializes the worker, informing it about the other workers in the
	// cluster and exchanging authentication tokens which will be used in all
	// other RPCs to detect whether the worker has restarted.
	CreateContext(context.Context, *CreateContextRequest) (*CreateContextResponse, error)
	// This takes a list of Execute and DeleteTensorHandle operations and enqueues
	// (in async mode) or executes (in sync mode) them on the remote server.
	// All outputs of ops which were not explicitly deleted with
	// DeleteTensorHandle entries will be assumed to be alive and are usable by
	// future calls to Enqueue.
	Enqueue(context.Context, *EnqueueRequest) (*EnqueueResponse, error)
	// Takes a set of op IDs and waits until those ops are done. Returns any error
	// in the stream so far.
	WaitQueueDone(context.Context, *WaitQueueDoneRequest) (*WaitQueueDoneResponse, error)
	// Contexts are always created with a deadline and no RPCs within a deadline
	// will trigger a context garbage collection. KeepAlive calls can be used to
	// delay this.
	KeepAlive(context.Context, *KeepAliveRequest) (*KeepAliveResponse, error)
	// Closes the context. No calls to other methods using the existing context ID
	// are valid after this.
	CloseContext(context.Context, *CloseContextRequest) (*CloseContextResponse, error)
	// Takes a FunctionDef and makes it enqueable on the remote worker.
	RegisterFunction(context.Context, *RegisterFunctionRequest) (*RegisterFunctionResponse, error)
	// An RPC to push tensors to the server. At times, certain environments don't
	// allow the server to connect back to the client.
	SendTensor(context.Context, *SendTensorRequest) (*SendTensorResponse, error)
}

func RegisterEagerServiceServer(s *grpc.Server, srv EagerServiceServer) {
	s.RegisterService(&_EagerService_serviceDesc, srv)
}

func _EagerService_CreateContext_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(CreateContextRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(EagerServiceServer).CreateContext(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/tensorflow.eager.EagerService/CreateContext",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(EagerServiceServer).CreateContext(ctx, req.(*CreateContextRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _EagerService_Enqueue_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(EnqueueRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(EagerServiceServer).Enqueue(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/tensorflow.eager.EagerService/Enqueue",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(EagerServiceServer).Enqueue(ctx, req.(*EnqueueRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _EagerService_WaitQueueDone_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(WaitQueueDoneRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(EagerServiceServer).WaitQueueDone(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/tensorflow.eager.EagerService/WaitQueueDone",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(EagerServiceServer).WaitQueueDone(ctx, req.(*WaitQueueDoneRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _EagerService_KeepAlive_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(KeepAliveRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(EagerServiceServer).KeepAlive(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/tensorflow.eager.EagerService/KeepAlive",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(EagerServiceServer).KeepAlive(ctx, req.(*KeepAliveRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _EagerService_CloseContext_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(CloseContextRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(EagerServiceServer).CloseContext(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/tensorflow.eager.EagerService/CloseContext",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(EagerServiceServer).CloseContext(ctx, req.(*CloseContextRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _EagerService_RegisterFunction_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(RegisterFunctionRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(EagerServiceServer).RegisterFunction(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/tensorflow.eager.EagerService/RegisterFunction",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(EagerServiceServer).RegisterFunction(ctx, req.(*RegisterFunctionRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _EagerService_SendTensor_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(SendTensorRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(EagerServiceServer).SendTensor(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/tensorflow.eager.EagerService/SendTensor",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(EagerServiceServer).SendTensor(ctx, req.(*SendTensorRequest))
	}
	return interceptor(ctx, in, info, handler)
}

var _EagerService_serviceDesc = grpc.ServiceDesc{
	ServiceName: "tensorflow.eager.EagerService",
	HandlerType: (*EagerServiceServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "CreateContext",
			Handler:    _EagerService_CreateContext_Handler,
		},
		{
			MethodName: "Enqueue",
			Handler:    _EagerService_Enqueue_Handler,
		},
		{
			MethodName: "WaitQueueDone",
			Handler:    _EagerService_WaitQueueDone_Handler,
		},
		{
			MethodName: "KeepAlive",
			Handler:    _EagerService_KeepAlive_Handler,
		},
		{
			MethodName: "CloseContext",
			Handler:    _EagerService_CloseContext_Handler,
		},
		{
			MethodName: "RegisterFunction",
			Handler:    _EagerService_RegisterFunction_Handler,
		},
		{
			MethodName: "SendTensor",
			Handler:    _EagerService_SendTensor_Handler,
		},
	},
	Streams:  []grpc.StreamDesc{},
	Metadata: "tensorflow/core/protobuf/eager_service.proto",
}

func init() {
	proto.RegisterFile("tensorflow/core/protobuf/eager_service.proto", fileDescriptor_eager_service_30fc3da5fde2e8e6)
}

var fileDescriptor_eager_service_30fc3da5fde2e8e6 = []byte{
	// 1036 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0x94, 0x56, 0xed, 0x72, 0xdb, 0x44,
	0x17, 0xae, 0x3f, 0xe4, 0xbe, 0x3e, 0x89, 0x53, 0x67, 0xf3, 0xe5, 0xd1, 0x4b, 0xa7, 0x41, 0x0d,
	0x21, 0x94, 0x62, 0x93, 0xd0, 0x19, 0x98, 0xd2, 0x3f, 0x69, 0x92, 0x12, 0xc3, 0x4c, 0x52, 0x36,
	0x99, 0x76, 0x60, 0x86, 0x51, 0x65, 0xe9, 0xd8, 0xd1, 0xc4, 0xd6, 0xaa, 0xab, 0x95, 0x4b, 0xf8,
	0xc7, 0x75, 0xf4, 0x1f, 0x97, 0xc1, 0x15, 0x71, 0x19, 0x8c, 0x76, 0x57, 0xfe, 0x92, 0x12, 0x9b,
	0x7f, 0xab, 0xb3, 0xcf, 0x73, 0xbe, 0xf6, 0x39, 0xbb, 0x82, 0xa7, 0x02, 0x83, 0x88, 0xf1, 0x6e,
	0x9f, 0x7d, 0x68, 0xb9, 0x8c, 0x63, 0x2b, 0xe4, 0x4c, 0xb0, 0x4e, 0xdc, 0x6d, 0xa1, 0xd3, 0x43,
	0x6e, 0x47, 0xc8, 0x87, 0xbe, 0x8b, 0x4d, 0x69, 0x26, 0xf5, 0x31, 0xba, 0x29, 0xf7, 0xcd, 0x27,
	0xb3, 0xfc, 0x2e, 0x77, 0x06, 0xf8, 0x81, 0xf1, 0xeb, 0x96, 0x23, 0x04, 0xb7, 0x87, 0x4e, 0x3f,
	0xd6, 0x6c, 0x73, 0xff, 0x76, 0xac, 0x87, 0x49, 0x14, 0x3b, 0xa1, 0xf8, 0x9d, 0x58, 0x60, 0xa4,
	0x29, 0x7b, 0xb7, 0x53, 0xba, 0x71, 0xe0, 0x0a, 0x9f, 0x05, 0xf3, 0x91, 0x43, 0xe4, 0x91, 0xcf,
	0x82, 0xd4, 0xe7, 0xd7, 0xb7, 0x96, 0x3c, 0xde, 0x90, 0x75, 0x23, 0xd7, 0x8c, 0xa7, 0xb7, 0xfb,
	0x56, 0x3b, 0x76, 0x74, 0xe5, 0x84, 0x69, 0x99, 0xbb, 0xf3, 0xd0, 0x0a, 0x67, 0x9d, 0x02, 0xa1,
	0x38, 0x60, 0x02, 0x2f, 0xa5, 0xf5, 0xd4, 0x09, 0xbc, 0x3e, 0x92, 0x35, 0x30, 0x58, 0x68, 0xfb,
	0x5e, 0xa3, 0xb0, 0x5d, 0xd8, 0x2b, 0xd1, 0x32, 0x0b, 0xdb, 0x1e, 0x79, 0x08, 0xc0, 0x62, 0x11,
	0xc6, 0xc2, 0x0e, 0xe2, 0x41, 0xa3, 0xb8, 0x5d, 0xd8, 0x33, 0x68, 0x55, 0x59, 0xce, 0xe2, 0x81,
	0xf5, 0x77, 0x11, 0xaa, 0xe7, 0x21, 0x72, 0x27, 0xe9, 0x07, 0x59, 0x81, 0xe2, 0x88, 0x5e, 0xf4,
	0x3d, 0x42, 0xa0, 0x1c, 0x38, 0x03, 0x94, 0xb4, 0x2a, 0x95, 0x6b, 0xf2, 0x02, 0x2a, 0x7e, 0x10,
	0xc6, 0x22, 0x6a, 0x94, 0xb6, 0x4b, 0x7b, 0x4b, 0x07, 0x3b, 0xcd, 0xd9, 0x93, 0x6d, 0x66, 0x73,
	0xa3, 0x9a, 0x43, 0x76, 0x60, 0xc5, 0x65, 0x81, 0xe0, 0xac, 0x6f, 0xcb, 0x5c, 0xa3, 0x46, 0x79,
	0xbb, 0xb4, 0x57, 0xa2, 0xcb, 0xda, 0x7a, 0x1e, 0xb6, 0xbd, 0x88, 0xbc, 0x00, 0x23, 0x39, 0xcf,
	0xa8, 0x61, 0xc8, 0x10, 0xbb, 0xd9, 0x10, 0xa3, 0x9c, 0x9b, 0x87, 0x09, 0xf0, 0x24, 0x10, 0xfc,
	0x86, 0x2a, 0x12, 0xd9, 0x84, 0x8a, 0x12, 0x45, 0xa3, 0x22, 0xf3, 0xd6, 0x5f, 0xe6, 0x39, 0xc0,
	0x18, 0x4c, 0xea, 0x50, 0xba, 0xc6, 0x1b, 0x59, 0x6c, 0x95, 0x26, 0x4b, 0xf2, 0x25, 0x18, 0x52,
	0x73, 0xb2, 0xdc, 0xa5, 0x83, 0x8d, 0xc9, 0xa8, 0x09, 0xf1, 0x4d, 0xb2, 0x49, 0x15, 0xe6, 0x79,
	0xf1, 0xbb, 0x82, 0xf5, 0x57, 0x01, 0xaa, 0x3f, 0xc7, 0x18, 0x63, 0x5b, 0xe0, 0x80, 0xbc, 0x86,
	0xfa, 0x95, 0x2c, 0xd6, 0x16, 0xcc, 0xf6, 0xd0, 0xe5, 0xd8, 0x95, 0xde, 0x17, 0x6c, 0xd1, 0xe9,
	0x3d, 0xba, 0xa2, 0xf8, 0x97, 0xec, 0x58, 0xb2, 0xc9, 0xf7, 0x50, 0x65, 0x69, 0x9d, 0x3a, 0xa9,
	0xff, 0xdf, 0xd1, 0x8a, 0xd3, 0x7b, 0x74, 0x8c, 0x7f, 0x59, 0x81, 0xb2, 0x2f, 0x70, 0x60, 0x1d,
	0x41, 0x4d, 0xe6, 0x48, 0x31, 0x0a, 0x59, 0x10, 0x21, 0x39, 0x00, 0x43, 0x6a, 0xae, 0x51, 0x90,
	0xcd, 0xfd, 0x64, 0xd2, 0xa3, 0x4a, 0xe8, 0x22, 0xd9, 0x7e, 0x9d, 0x28, 0x8d, 0x2a, 0xa8, 0xf5,
	0x4f, 0x01, 0xd6, 0x8f, 0x38, 0x3a, 0x02, 0x8f, 0x58, 0x20, 0xf0, 0x77, 0x41, 0xf1, 0x7d, 0x8c,
	0x91, 0x20, 0xcf, 0x00, 0x94, 0xde, 0x6d, 0x6f, 0x54, 0xee, 0x54, 0xe3, 0x2e, 0xe4, 0xee, 0x31,
	0x76, 0x69, 0x35, 0x4a, 0x97, 0x64, 0x1d, 0x0c, 0x27, 0xba, 0x09, 0x5c, 0x59, 0xd4, 0xff, 0xa8,
	0xfa, 0x20, 0xbb, 0xf0, 0xe0, 0x1a, 0x31, 0xb4, 0x9d, 0xbe, 0x3f, 0x44, 0x3b, 0x42, 0x37, 0x91,
	0x58, 0x22, 0xc5, 0x5a, 0x62, 0x3e, 0x4c, 0xac, 0x17, 0xe8, 0x46, 0xe4, 0x5b, 0x58, 0xd2, 0x73,
	0x29, 0x83, 0x96, 0x65, 0xd0, 0xcd, 0xc9, 0xa0, 0x6f, 0xd4, 0x76, 0x12, 0x15, 0x86, 0xa3, 0x35,
	0x79, 0x0c, 0x35, 0x8e, 0x81, 0x87, 0x7f, 0x0c, 0x59, 0x1c, 0x25, 0x83, 0x62, 0x48, 0xf7, 0xcb,
	0x63, 0x63, 0xdb, 0xb3, 0xfe, 0x2c, 0xc0, 0xc6, 0x4c, 0xa9, 0xba, 0x71, 0x0f, 0x01, 0x5c, 0x65,
	0x4a, 0x87, 0xac, 0x42, 0xab, 0xda, 0xd2, 0xf6, 0x48, 0x1b, 0x56, 0x33, 0x77, 0x51, 0xa3, 0x98,
	0xed, 0xf1, 0xb1, 0x04, 0x1d, 0x8e, 0x30, 0xb4, 0xee, 0xcd, 0x58, 0xac, 0x0e, 0xac, 0x9c, 0x04,
	0xef, 0xd5, 0xa9, 0xa9, 0x3e, 0xcf, 0x89, 0xbd, 0x0f, 0x86, 0x84, 0xeb, 0x99, 0xcc, 0x51, 0xc9,
	0x48, 0xa7, 0x54, 0x21, 0xad, 0x5f, 0xe0, 0xc1, 0x28, 0x86, 0x2e, 0xf0, 0x15, 0xac, 0x48, 0x83,
	0xcd, 0xb5, 0x45, 0x4b, 0xe4, 0xd1, 0x2d, 0xee, 0x52, 0x22, 0xad, 0x4d, 0xf9, 0xb1, 0x7e, 0x84,
	0xf5, 0xb7, 0x8e, 0x2f, 0x24, 0xe6, 0x98, 0x05, 0x8b, 0x16, 0x31, 0xba, 0xbf, 0x8a, 0xf2, 0x4a,
	0x90, 0xf7, 0x97, 0xb5, 0x05, 0x1b, 0x33, 0xbe, 0x74, 0x90, 0x7d, 0xa8, 0xff, 0x94, 0xca, 0x62,
	0xb1, 0x00, 0xd6, 0x1a, 0xac, 0x4e, 0x50, 0xb4, 0x9f, 0x67, 0xb0, 0x76, 0xd4, 0x67, 0xd1, 0xac,
	0xb0, 0xe7, 0xb8, 0xda, 0x84, 0xf5, 0x69, 0x96, 0xf6, 0x26, 0x60, 0x8b, 0x62, 0xcf, 0x8f, 0x04,
	0xf2, 0x57, 0xfa, 0x95, 0x59, 0xb0, 0xfa, 0xe7, 0xb0, 0x9c, 0xbe, 0x4b, 0x52, 0xd6, 0x6a, 0xde,
	0xb7, 0x26, 0x5b, 0x9f, 0x7a, 0x4c, 0x74, 0xbd, 0xd4, 0x1d, 0x7f, 0x58, 0x26, 0x34, 0xb2, 0x51,
	0x75, 0x46, 0x1f, 0x0b, 0xb0, 0x7a, 0x81, 0x81, 0xa7, 0x46, 0xfb, 0xbf, 0x1f, 0xc5, 0xf8, 0x29,
	0xd9, 0x87, 0xfb, 0x2a, 0x99, 0xf4, 0xea, 0xdf, 0xca, 0x5e, 0x1d, 0xea, 0xd6, 0x48, 0x71, 0xe4,
	0x11, 0x2c, 0xe9, 0x99, 0x90, 0xef, 0x48, 0x59, 0x5e, 0xb6, 0xa0, 0x4c, 0x67, 0xce, 0x00, 0xad,
	0x75, 0x20, 0x93, 0xc9, 0xa9, 0x9c, 0x0f, 0x3e, 0x1a, 0xb0, 0x7c, 0x92, 0xe8, 0xec, 0x42, 0xfd,
	0x43, 0x90, 0x77, 0x50, 0x9b, 0x9a, 0x49, 0x92, 0xf3, 0x24, 0xe4, 0xdd, 0x4f, 0xe6, 0xe7, 0x73,
	0x71, 0x5a, 0xfb, 0x67, 0x70, 0x5f, 0x8f, 0x03, 0xd9, 0xce, 0x72, 0xa6, 0xa7, 0xd1, 0xfc, 0xf4,
	0x0e, 0x84, 0xf6, 0xf7, 0x0e, 0x6a, 0x53, 0xba, 0xcd, 0xcb, 0x38, 0x6f, 0x48, 0xf2, 0x32, 0xce,
	0x1d, 0x00, 0x72, 0x09, 0xd5, 0x91, 0x9a, 0x89, 0x95, 0x65, 0xcd, 0x4e, 0x87, 0xf9, 0xf8, 0x4e,
	0x8c, 0xf6, 0xfa, 0x1b, 0x2c, 0x4f, 0x0a, 0x9b, 0x7c, 0x96, 0xd3, 0xc0, 0xec, 0xb8, 0x98, 0xbb,
	0xf3, 0x60, 0xda, 0xbd, 0x0f, 0xf5, 0x59, 0xa5, 0x92, 0x2f, 0xf2, 0x9e, 0xc7, 0xdc, 0x19, 0x32,
	0x9f, 0x2c, 0x02, 0xd5, 0xa1, 0xde, 0x02, 0x8c, 0xa5, 0x45, 0x72, 0x8a, 0xcf, 0x4c, 0x85, 0xb9,
	0x73, 0x37, 0x48, 0x39, 0x7e, 0xf9, 0xc3, 0xaf, 0x27, 0x3d, 0x5f, 0x5c, 0xc5, 0x9d, 0xa6, 0xcb,
	0x06, 0xad, 0x00, 0x45, 0x87, 0x3b, 0x7e, 0xd0, 0x12, 0xdd, 0xaf, 0x7a, 0x3c, 0x74, 0x5b, 0x3d,
	0x36, 0xf1, 0x37, 0x38, 0xb9, 0xec, 0xb1, 0xe9, 0x9f, 0xc6, 0x4e, 0x45, 0xae, 0xbe, 0xf9, 0x37,
	0x00, 0x00, 0xff, 0xff, 0x6f, 0xef, 0xd6, 0xc1, 0x4a, 0x0b, 0x00, 0x00,
}
