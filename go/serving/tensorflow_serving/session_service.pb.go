// Code generated by protoc-gen-go. DO NOT EDIT.
// source: tensorflow_serving/apis/session_service.proto

package tensorflow_serving // import "github.com/netbrain/tf-grpc/go/serving/tensorflow_serving"

import proto "github.com/golang/protobuf/proto"
import fmt "fmt"
import math "math"
import protobuf "github.com/netbrain/tf-grpc/go/tensorflow/tensorflow/go/core/protobuf"

import (
	context "golang.org/x/net/context"
	grpc "google.golang.org/grpc"
)

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

// This is a compile-time assertion to ensure that this generated file
// is compatible with the proto package it is being compiled against.
// A compilation error at this line likely means your copy of the
// proto package needs to be updated.
const _ = proto.ProtoPackageIsVersion2 // please upgrade the proto package

type SessionRunRequest struct {
	// Model Specification. If version is not specified, will use the latest
	// (numerical) version.
	ModelSpec *ModelSpec `protobuf:"bytes,1,opt,name=model_spec,json=modelSpec,proto3" json:"model_spec,omitempty"`
	// Tensors to be fed in the step. Each feed is a named tensor.
	Feed []*protobuf.NamedTensorProto `protobuf:"bytes,2,rep,name=feed,proto3" json:"feed,omitempty"`
	// Fetches. A list of tensor names. The caller expects a tensor to
	// be returned for each fetch[i] (see RunResponse.tensor). The
	// order of specified fetches does not change the execution order.
	Fetch []string `protobuf:"bytes,3,rep,name=fetch,proto3" json:"fetch,omitempty"`
	// Target Nodes. A list of node names. The named nodes will be run
	// to but their outputs will not be fetched.
	Target []string `protobuf:"bytes,4,rep,name=target,proto3" json:"target,omitempty"`
	// Options for the run call. **Currently ignored.**
	Options              *protobuf.RunOptions `protobuf:"bytes,5,opt,name=options,proto3" json:"options,omitempty"`
	XXX_NoUnkeyedLiteral struct{}             `json:"-"`
	XXX_unrecognized     []byte               `json:"-"`
	XXX_sizecache        int32                `json:"-"`
}

func (m *SessionRunRequest) Reset()         { *m = SessionRunRequest{} }
func (m *SessionRunRequest) String() string { return proto.CompactTextString(m) }
func (*SessionRunRequest) ProtoMessage()    {}
func (*SessionRunRequest) Descriptor() ([]byte, []int) {
	return fileDescriptor_session_service_4f0c5060686d7645, []int{0}
}
func (m *SessionRunRequest) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_SessionRunRequest.Unmarshal(m, b)
}
func (m *SessionRunRequest) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_SessionRunRequest.Marshal(b, m, deterministic)
}
func (dst *SessionRunRequest) XXX_Merge(src proto.Message) {
	xxx_messageInfo_SessionRunRequest.Merge(dst, src)
}
func (m *SessionRunRequest) XXX_Size() int {
	return xxx_messageInfo_SessionRunRequest.Size(m)
}
func (m *SessionRunRequest) XXX_DiscardUnknown() {
	xxx_messageInfo_SessionRunRequest.DiscardUnknown(m)
}

var xxx_messageInfo_SessionRunRequest proto.InternalMessageInfo

func (m *SessionRunRequest) GetModelSpec() *ModelSpec {
	if m != nil {
		return m.ModelSpec
	}
	return nil
}

func (m *SessionRunRequest) GetFeed() []*protobuf.NamedTensorProto {
	if m != nil {
		return m.Feed
	}
	return nil
}

func (m *SessionRunRequest) GetFetch() []string {
	if m != nil {
		return m.Fetch
	}
	return nil
}

func (m *SessionRunRequest) GetTarget() []string {
	if m != nil {
		return m.Target
	}
	return nil
}

func (m *SessionRunRequest) GetOptions() *protobuf.RunOptions {
	if m != nil {
		return m.Options
	}
	return nil
}

type SessionRunResponse struct {
	// Effective Model Specification used for session run.
	ModelSpec *ModelSpec `protobuf:"bytes,3,opt,name=model_spec,json=modelSpec,proto3" json:"model_spec,omitempty"`
	// NOTE: The order of the returned tensors may or may not match
	// the fetch order specified in RunRequest.
	Tensor []*protobuf.NamedTensorProto `protobuf:"bytes,1,rep,name=tensor,proto3" json:"tensor,omitempty"`
	// Returned metadata if requested in the options.
	Metadata             *protobuf.RunMetadata `protobuf:"bytes,2,opt,name=metadata,proto3" json:"metadata,omitempty"`
	XXX_NoUnkeyedLiteral struct{}              `json:"-"`
	XXX_unrecognized     []byte                `json:"-"`
	XXX_sizecache        int32                 `json:"-"`
}

func (m *SessionRunResponse) Reset()         { *m = SessionRunResponse{} }
func (m *SessionRunResponse) String() string { return proto.CompactTextString(m) }
func (*SessionRunResponse) ProtoMessage()    {}
func (*SessionRunResponse) Descriptor() ([]byte, []int) {
	return fileDescriptor_session_service_4f0c5060686d7645, []int{1}
}
func (m *SessionRunResponse) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_SessionRunResponse.Unmarshal(m, b)
}
func (m *SessionRunResponse) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_SessionRunResponse.Marshal(b, m, deterministic)
}
func (dst *SessionRunResponse) XXX_Merge(src proto.Message) {
	xxx_messageInfo_SessionRunResponse.Merge(dst, src)
}
func (m *SessionRunResponse) XXX_Size() int {
	return xxx_messageInfo_SessionRunResponse.Size(m)
}
func (m *SessionRunResponse) XXX_DiscardUnknown() {
	xxx_messageInfo_SessionRunResponse.DiscardUnknown(m)
}

var xxx_messageInfo_SessionRunResponse proto.InternalMessageInfo

func (m *SessionRunResponse) GetModelSpec() *ModelSpec {
	if m != nil {
		return m.ModelSpec
	}
	return nil
}

func (m *SessionRunResponse) GetTensor() []*protobuf.NamedTensorProto {
	if m != nil {
		return m.Tensor
	}
	return nil
}

func (m *SessionRunResponse) GetMetadata() *protobuf.RunMetadata {
	if m != nil {
		return m.Metadata
	}
	return nil
}

func init() {
	proto.RegisterType((*SessionRunRequest)(nil), "tensorflow.serving.SessionRunRequest")
	proto.RegisterType((*SessionRunResponse)(nil), "tensorflow.serving.SessionRunResponse")
}

// Reference imports to suppress errors if they are not otherwise used.
var _ context.Context
var _ grpc.ClientConn

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
const _ = grpc.SupportPackageIsVersion4

// SessionServiceClient is the client API for SessionService service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://godoc.org/google.golang.org/grpc#ClientConn.NewStream.
type SessionServiceClient interface {
	// Runs inference of a given model.
	SessionRun(ctx context.Context, in *SessionRunRequest, opts ...grpc.CallOption) (*SessionRunResponse, error)
}

type sessionServiceClient struct {
	cc *grpc.ClientConn
}

func NewSessionServiceClient(cc *grpc.ClientConn) SessionServiceClient {
	return &sessionServiceClient{cc}
}

func (c *sessionServiceClient) SessionRun(ctx context.Context, in *SessionRunRequest, opts ...grpc.CallOption) (*SessionRunResponse, error) {
	out := new(SessionRunResponse)
	err := c.cc.Invoke(ctx, "/tensorflow.serving.SessionService/SessionRun", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// SessionServiceServer is the server API for SessionService service.
type SessionServiceServer interface {
	// Runs inference of a given model.
	SessionRun(context.Context, *SessionRunRequest) (*SessionRunResponse, error)
}

func RegisterSessionServiceServer(s *grpc.Server, srv SessionServiceServer) {
	s.RegisterService(&_SessionService_serviceDesc, srv)
}

func _SessionService_SessionRun_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(SessionRunRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(SessionServiceServer).SessionRun(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/tensorflow.serving.SessionService/SessionRun",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(SessionServiceServer).SessionRun(ctx, req.(*SessionRunRequest))
	}
	return interceptor(ctx, in, info, handler)
}

var _SessionService_serviceDesc = grpc.ServiceDesc{
	ServiceName: "tensorflow.serving.SessionService",
	HandlerType: (*SessionServiceServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "SessionRun",
			Handler:    _SessionService_SessionRun_Handler,
		},
	},
	Streams:  []grpc.StreamDesc{},
	Metadata: "tensorflow_serving/apis/session_service.proto",
}

func init() {
	proto.RegisterFile("tensorflow_serving/apis/session_service.proto", fileDescriptor_session_service_4f0c5060686d7645)
}

var fileDescriptor_session_service_4f0c5060686d7645 = []byte{
	// 380 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0x94, 0x92, 0xc1, 0x4e, 0xea, 0x40,
	0x14, 0x86, 0x53, 0x0a, 0xdc, 0xcb, 0x90, 0xdc, 0xe4, 0x4e, 0x0c, 0x36, 0x44, 0x13, 0x82, 0xc1,
	0x90, 0x18, 0x3a, 0x04, 0xdc, 0x98, 0x18, 0x17, 0xee, 0x51, 0x33, 0xb8, 0xd2, 0x05, 0x69, 0xa7,
	0xa7, 0xa5, 0x09, 0x9d, 0xa9, 0x33, 0x53, 0x7d, 0x3a, 0x9f, 0xc6, 0x97, 0x70, 0x69, 0x98, 0x29,
	0x42, 0x40, 0xa2, 0xee, 0x7a, 0xce, 0xf9, 0x4e, 0xcf, 0xff, 0xb7, 0x3f, 0x1a, 0x68, 0xe0, 0x4a,
	0xc8, 0x78, 0x21, 0x5e, 0x66, 0x0a, 0xe4, 0x73, 0xca, 0x13, 0x12, 0xe4, 0xa9, 0x22, 0x0a, 0x94,
	0x4a, 0x05, 0xb7, 0x4d, 0x06, 0x7e, 0x2e, 0x85, 0x16, 0x18, 0xaf, 0x71, 0xbf, 0xc4, 0xdb, 0x27,
	0xfb, 0x5e, 0x91, 0x89, 0x08, 0x16, 0x76, 0xb1, 0xdd, 0x5b, 0x43, 0x84, 0x09, 0x09, 0xc4, 0xb4,
	0xc3, 0x22, 0x26, 0x4c, 0xf0, 0x38, 0x4d, 0x4a, 0xec, 0x6c, 0x2f, 0xc6, 0x83, 0x0c, 0xa2, 0x99,
	0x1d, 0x5b, 0xb8, 0xfb, 0xe6, 0xa0, 0xff, 0x53, 0x2b, 0x93, 0x16, 0x9c, 0xc2, 0x53, 0x01, 0x4a,
	0xe3, 0x4b, 0x84, 0xcc, 0xe1, 0x99, 0xca, 0x81, 0x79, 0x4e, 0xc7, 0xe9, 0x37, 0x47, 0xc7, 0xfe,
	0xae, 0x6e, 0x7f, 0xb2, 0xa4, 0xa6, 0x39, 0x30, 0xda, 0xc8, 0x56, 0x8f, 0x78, 0x88, 0xaa, 0x31,
	0x40, 0xe4, 0x55, 0x3a, 0x6e, 0xbf, 0x39, 0x3a, 0xda, 0xdc, 0xbb, 0x59, 0x2a, 0xb8, 0x37, 0xf5,
	0xdd, 0xf2, 0x3e, 0x35, 0x24, 0x3e, 0x40, 0xb5, 0x18, 0x34, 0x9b, 0x7b, 0x6e, 0xc7, 0xed, 0x37,
	0xa8, 0x2d, 0x70, 0x0b, 0xd5, 0x75, 0x20, 0x13, 0xd0, 0x5e, 0xd5, 0xb4, 0xcb, 0x0a, 0x0f, 0xd1,
	0x1f, 0x91, 0xeb, 0x54, 0x70, 0xe5, 0xd5, 0x8c, 0xb4, 0xd6, 0xe6, 0x09, 0x5a, 0xf0, 0x5b, 0x3b,
	0xa5, 0x2b, 0xac, 0xfb, 0xea, 0x20, 0xbc, 0xe9, 0x52, 0xe5, 0x82, 0x2b, 0xd8, 0xb2, 0xe9, 0xfe,
	0xd2, 0xe6, 0x39, 0xaa, 0x5b, 0xd4, 0x73, 0x7e, 0x60, 0xb4, 0x64, 0xf1, 0x18, 0xfd, 0xcd, 0x40,
	0x07, 0x51, 0xa0, 0x03, 0xaf, 0x62, 0x2e, 0x1e, 0x6e, 0xa9, 0x9f, 0x94, 0x63, 0xfa, 0x09, 0x8e,
	0x32, 0xf4, 0xaf, 0x94, 0x3f, 0xb5, 0x51, 0xc2, 0x8f, 0x08, 0xad, 0x0d, 0xe1, 0xde, 0x57, 0xa2,
	0x77, 0x7e, 0x6b, 0xfb, 0xf4, 0x3b, 0xcc, 0x7e, 0x97, 0xeb, 0xab, 0x87, 0x8b, 0x24, 0xd5, 0xf3,
	0x22, 0xf4, 0x99, 0xc8, 0x08, 0x07, 0x1d, 0xca, 0x20, 0xe5, 0x44, 0xc7, 0x83, 0x44, 0xe6, 0x8c,
	0x24, 0x82, 0xac, 0x32, 0xba, 0x1b, 0xdb, 0x77, 0xc7, 0x09, 0xeb, 0x26, 0x5b, 0xe3, 0x8f, 0x00,
	0x00, 0x00, 0xff, 0xff, 0x34, 0xa2, 0x89, 0xc8, 0x19, 0x03, 0x00, 0x00,
}
